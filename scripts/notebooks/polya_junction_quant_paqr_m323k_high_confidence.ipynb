{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying poly(A) sites as junction counts relative to 5' TE splice junction\n",
    "\n",
    "\n",
    "The throw it out there idea is that if this is reliable (i.e. just considering counts across poly(A) sites (accounting for minimum overhang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr', 'cluster_start', 'cluster_end', 'site_id', 'score', 'strand', 'n_along_exon', 'total_sites_on_exon', 'paqr_exon_id', 'gene_id', 'M323K_WT_1', 'M323K_HOM_1', 'M323K_WT_2', 'M323K_HOM_2', 'M323K_WT_3', 'M323K_HOM_3', 'M323K_WT_4', 'M323K_HOM_4', 'M323K_WT_1', 'M323K_HOM_5']\n",
      "{'M323K_HOM_4', 'M323K_WT_1', 'M323K_HOM_5', 'M323K_HOM_1', 'M323K_HOM_3', 'M323K_WT_2', 'M323K_WT_4', 'M323K_HOM_2', 'M323K_WT_3'}\n",
      "        chr  cluster_start  cluster_end               site_id  score strand  \\\n",
      "0     chr16       20544628     20544662   chr16:+:20544651:TE      4      +   \n",
      "1      chrX      133931787    133931831   chrX:+:133931813:TE      7      +   \n",
      "2      chrX      133932295    133932296   chrX:+:133932296:TE      1      +   \n",
      "3     chr17       75390823     75390843   chr17:+:75390843:TE      1      +   \n",
      "4     chr17       75391754     75391779   chr17:+:75391769:TE      8      +   \n",
      "...     ...            ...          ...                   ...    ...    ...   \n",
      "3498   chr1      171388592    171388593   chr1:+:171388593:TE      1      +   \n",
      "3499  chr18       10817819     10817820   chr18:+:10817820:TE      1      +   \n",
      "3500  chr18       10818545     10818591   chr18:+:10818572:TE      9      +   \n",
      "3501  chr11      105281885    105281910  chr11:+:105281900:TE      9      +   \n",
      "3502  chr11      105282139    105282187  chr11:+:105282176:TE      9      +   \n",
      "\n",
      "      n_along_exon  total_sites_on_exon  \\\n",
      "0                2                    2   \n",
      "1                1                    2   \n",
      "2                2                    2   \n",
      "3                1                    2   \n",
      "4                2                    2   \n",
      "...            ...                  ...   \n",
      "3498             2                    2   \n",
      "3499             1                    2   \n",
      "3500             2                    2   \n",
      "3501             1                    2   \n",
      "3502             2                    2   \n",
      "\n",
      "                                      paqr_exon_id             gene_id  \\\n",
      "0       ENSMUST00000007216:12:12:20543310:20544909  ENSMUST00000007216   \n",
      "1     ENSMUST00000113304:11:11:133931285:133932446  ENSMUST00000113304   \n",
      "2     ENSMUST00000113304:11:11:133931285:133932446  ENSMUST00000113304   \n",
      "3       ENSMUST00000001927:34:34:75390371:75391767  ENSMUST00000001927   \n",
      "4       ENSMUST00000001927:34:34:75390371:75391767  ENSMUST00000001927   \n",
      "...                                            ...                 ...   \n",
      "3498    ENSMUST00000006578:9:9:171386580:171388598  ENSMUST00000006578   \n",
      "3499    ENSMUST00000124288:15:15:10817818:10818704  ENSMUST00000124288   \n",
      "3500    ENSMUST00000124288:15:15:10817818:10818704  ENSMUST00000124288   \n",
      "3501  ENSMUST00000015107:21:21:105281084:105282176  ENSMUST00000015107   \n",
      "3502  ENSMUST00000015107:21:21:105281084:105282176  ENSMUST00000015107   \n",
      "\n",
      "      M323K_WT_1  M323K_HOM_1  M323K_WT_2  M323K_HOM_2  M323K_WT_3  \\\n",
      "0           1.24         0.94        1.01         0.96        1.20   \n",
      "1          77.90        80.29       84.12        87.88       84.79   \n",
      "2          22.10        19.71       15.88        12.12       15.21   \n",
      "3          53.87        57.71       59.07        56.42       54.81   \n",
      "4          46.13        42.29       40.93        43.58       45.19   \n",
      "...          ...          ...         ...          ...         ...   \n",
      "3498        0.00         0.00        0.00         1.28        1.28   \n",
      "3499       73.28         0.00       76.02        69.25       75.55   \n",
      "3500       26.72       100.00       23.98        30.75       24.45   \n",
      "3501       42.12        34.75       32.73        33.24       39.23   \n",
      "3502       57.88        65.25       67.27        66.76       60.77   \n",
      "\n",
      "      M323K_HOM_3  M323K_WT_4  M323K_HOM_4  M323K_WT_1  M323K_HOM_5  \n",
      "0            0.90        0.71         0.99        1.24         1.34  \n",
      "1           88.57       82.14        91.22       77.90        66.57  \n",
      "2           11.43       17.86         8.78       22.10        33.43  \n",
      "3           50.26       52.27        38.13       53.87        46.96  \n",
      "4           49.74       47.73        61.87       46.13        53.04  \n",
      "...           ...         ...          ...         ...          ...  \n",
      "3498         0.00        0.00         1.67        0.00         0.88  \n",
      "3499        79.37       74.77        79.20       73.28        77.80  \n",
      "3500        20.63       25.23        20.80       26.72        22.20  \n",
      "3501        39.73       45.41        45.51       42.12        35.87  \n",
      "3502        60.27       54.59        54.49       57.88        64.13  \n",
      "\n",
      "[3503 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pysam\n",
    "os.getcwd()\n",
    "\n",
    "paqr_rel_usages_path = \"../../data/relative_usages.filtered.tsv\"\n",
    "rel_usages_header_path = \"../../data/relative_usages.header.out\"\n",
    "m323k_wt_1_bam_path = \"/home/sam/cluster/TDP43_RNA/TDP_F210I_M323K/M323K/New_adult_brain/processed/M323K_WT_1/M323K_WT_1_unique_rg_fixed.bam\"\n",
    "m323k_hom_1_bam_path = \"/home/sam/cluster/TDP43_RNA/TDP_F210I_M323K/M323K/New_adult_brain/processed/M323K_HOM_1/M323K_HOM_1_unique_rg_fixed.bam\"\n",
    "\n",
    "rel_usages = pd.read_csv(paqr_rel_usages_path,sep=\"\\t\")\n",
    "\n",
    "with open(rel_usages_header_path) as inpt:\n",
    "    \n",
    "    sample_names = [line.rstrip() for line in inpt]\n",
    "\n",
    "\n",
    "#print(rel_usages)\n",
    "#print(sample_names)\n",
    "\n",
    "#First 10 columns are the same in relative usages df\n",
    "colnames_rel_usages = [\"chr\",\n",
    " \"cluster_start\",\n",
    " \"cluster_end\",\n",
    " \"site_id\",\n",
    " \"score\",\n",
    " \"strand\",\n",
    " \"n_along_exon\",\n",
    " \"total_sites_on_exon\", \n",
    " \"paqr_exon_id\", \n",
    " \"gene_id\" # this is technically transcript_id but for now I'll leave it...\n",
    "]\n",
    "\n",
    "#Rest of columns are samples names in order found in relative usages output df\n",
    "colnames_rel_usages.extend(sample_names)\n",
    "\n",
    "print(colnames_rel_usages)\n",
    "\n",
    "\n",
    "#Because samples are paired according to config - can appear multiple times in df...\n",
    "sample_names = set(sample_names)\n",
    "print(sample_names)\n",
    "\n",
    "rel_usages.columns = colnames_rel_usages\n",
    "print(rel_usages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#grouped = rel_usages.groupby(\"gene_id\")\n",
    "#print(grouped)\n",
    "\n",
    "#for a, b in grouped:\n",
    "#    print(a)\n",
    "#    print(b[\"site_id\"].to_list())\n",
    "\n",
    "    \n",
    "    \n",
    "def polyASite_id_to_coordinate_tuple(paqr_df, site_id_colname = \"site_id\", group_col = \"gene_id\"):\n",
    "    '''\n",
    "    Nested dict of {<group_col_key>: {site_id: (chr, start, end)}}}\n",
    "    Assume coord is 1 based, output will be 0 based, 1/2 open\n",
    "    '''\n",
    "    \n",
    "    df_grouped = paqr_df.groupby(group_col)\n",
    "    \n",
    "    out_dict = {}\n",
    "    \n",
    "    for group_name, group in df_grouped:\n",
    "        \n",
    "        site_ids = group[site_id_colname].to_list()\n",
    "        nested_dict = {}\n",
    "        \n",
    "        for site in site_ids:\n",
    "            #'chr11:+:55110898:TE'\n",
    "            ID = site.split(':')\n",
    "            seq_tuple = (ID[0], int(ID[2]), int(ID[2]) + 1)\n",
    "            \n",
    "            nested_dict[site] = seq_tuple \n",
    "            \n",
    "        out_dict[group_name] = nested_dict\n",
    "        \n",
    "        \n",
    "    return out_dict\n",
    "\n",
    "\n",
    "polya_jnc_coords = polyASite_id_to_coordinate_tuple(rel_usages)\n",
    "#print(polya_jnc_coords)\n",
    "\n",
    "\n",
    "### For testing, let's just look at a few transcripts\n",
    "small_polya_jnc_coords = {key: polya_jnc_coords[key] for key in list(polya_jnc_coords.keys())[:5]}\n",
    "#print(small_polya_jnc_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I've got my PAQR inferred/ PolyASite poly(A) sites , I want to try and count the number of reads that span these positions - 'junction reads'\n",
    "\n",
    "As I will want to quantify these junctions relative to the splice junction at the 5'end of the terminal exon, I have to treat the poly(A) junction alignments as if they were a splice junction (where sequence is disjointly aligned to the genome\n",
    "\n",
    "STAR (and likely other splice-aware aligners) has a --alignSJDBoverhangMin parameter, which requires that a putative junction read 'overhangs' the junction by at least x nt (x = 3 by default) in orfer for it to be assigned to the junction\n",
    "\n",
    "\n",
    "Reads aligned to genome at poly(A) sites aren't subject to this parameter, so junction counts would be inflated relative to the 5' splice junction\n",
    "\n",
    "\n",
    "using pysam, for each read crossing the poly(A) site, check whether start or end of read alignment falls within 3nt of the poly(A) site coordinate\n",
    "\n",
    "abs(polya_site - alignment_start) > 3 and abs(alignment_end - polya_site) > 3 = valid poly(A) site junction read\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENSMUST00000000608': {'chr11:+:55110898:TE': 3, 'chr11:+:55113026:TE': 1}, 'ENSMUST00000000844': {'chr2:+:181515384:TE': 212, 'chr2:+:181515774:TE': 102, 'chr2:+:181516756:TE': 26}, 'ENSMUST00000000896': {'chr2:-:154587124:TE': 16, 'chr2:-:154585759:TE': 0}, 'ENSMUST00000000985': {'chr14:+:54368610:TE': 64, 'chr14:+:54369669:TE': 4}, 'ENSMUST00000001079': {'chr3:-:129983184:TE': 49, 'chr3:-:129982765:TE': 1}}\n",
      "{'ENSMUST00000000608': {'chr11:+:55110898:TE': 3, 'chr11:+:55113026:TE': 1}, 'ENSMUST00000000844': {'chr2:+:181515384:TE': 212, 'chr2:+:181515774:TE': 102, 'chr2:+:181516756:TE': 26}, 'ENSMUST00000000896': {'chr2:-:154587124:TE': 16, 'chr2:-:154585759:TE': 0}, 'ENSMUST00000000985': {'chr14:+:54368610:TE': 64, 'chr14:+:54369669:TE': 4}, 'ENSMUST00000001079': {'chr3:-:129983184:TE': 49, 'chr3:-:129982765:TE': 1}}\n",
      "5\n",
      "5\n",
      "{'ENSMUST00000000608': {'chr11:+:55110898:TE': 3, 'chr11:+:55113026:TE': 1}, 'ENSMUST00000000844': {'chr2:+:181515384:TE': 212, 'chr2:+:181515774:TE': 102, 'chr2:+:181516756:TE': 26}, 'ENSMUST00000000896': {'chr2:-:154587124:TE': 16, 'chr2:-:154585759:TE': 0}, 'ENSMUST00000000985': {'chr14:+:54368610:TE': 64, 'chr14:+:54369669:TE': 4}, 'ENSMUST00000001079': {'chr3:-:129983184:TE': 49, 'chr3:-:129982765:TE': 1}}\n",
      "{'ENSMUST00000000608': {'chr11:+:55110898:TE': 2, 'chr11:+:55113026:TE': 0}, 'ENSMUST00000000844': {'chr2:+:181515384:TE': 268, 'chr2:+:181515774:TE': 90, 'chr2:+:181516756:TE': 27}, 'ENSMUST00000000896': {'chr2:-:154587124:TE': 20, 'chr2:-:154585759:TE': 0}, 'ENSMUST00000000985': {'chr14:+:54368610:TE': 66, 'chr14:+:54369669:TE': 15}, 'ENSMUST00000001079': {'chr3:-:129983184:TE': 51, 'chr3:-:129982765:TE': 0}}\n"
     ]
    }
   ],
   "source": [
    "#WT 1\n",
    "\n",
    "wt_1 = pysam.AlignmentFile(m323k_wt_1_bam_path, \"rb\")\n",
    "\n",
    "\n",
    "jnc_counts_dict = {}\n",
    "\n",
    "for transcript, polya_dict in small_polya_jnc_coords.items():\n",
    "    # store junction read counts for every poly(A) site in transcript\n",
    "    tr_polya_dict = {}\n",
    "    #print(polya_dict)\n",
    "    \n",
    "    for polya_site, coords_tuple in polya_dict.items():\n",
    "        \n",
    "        #Reads overlapping poly(A) site\n",
    "        site_jnc_read_count = 0\n",
    "        \n",
    "        for read_entry in wt_1.fetch(coords_tuple[0], coords_tuple[1], coords_tuple[2]):\n",
    "            \n",
    "            #0-based leftmost reference coordinate of the aligned sequence\n",
    "            align_start = read_entry.reference_start\n",
    "            \n",
    "            # Aligned reference position of the read on the reference genome.\n",
    "            # Reference_end points to one past the last aligned residue. Returns None if not available (read is unmapped or no cigar alignment present).\n",
    "\n",
    "            align_end = read_entry.reference_end\n",
    "            \n",
    "            #print(read_entry.query_name)\n",
    "            #print(\"align_start: {0}, align_end: {1}\".format(str(align_start), str(align_end)))\n",
    "            \n",
    "            #polyA site - align_start & align_end - polya_site\n",
    "            if abs(coords_tuple[1] - align_start) > 3 and abs(align_end - coords_tuple[1]) > 3:\n",
    "                site_jnc_read_count += 1\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        #Now have checked every read overlapping poly(A) site\n",
    "        tr_polya_dict[polya_site] = site_jnc_read_count\n",
    "        \n",
    "    \n",
    "    #Now have counted junction reads for each poly(A) site in transcript\n",
    "    jnc_counts_dict[transcript] = tr_polya_dict\n",
    "    \n",
    "    \n",
    "\n",
    "#print(jnc_counts_dict)\n",
    "\n",
    "\n",
    "def is_polya_junction_read(read_entry,polya_start, sj_overhang):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #0-based leftmost reference coordinate of the aligned sequence\n",
    "    align_start = read_entry.reference_start\n",
    "           \n",
    "    # Aligned reference position of the read on the reference genome.\n",
    "    # Reference_end points to one past the last aligned residue. Returns None if not available (read is unmapped or no cigar alignment present).\n",
    "\n",
    "    align_end = read_entry.reference_end\n",
    "    \n",
    "    if abs(polya_start - align_start) > sj_overhang and abs(align_end - polya_start) > sj_overhang:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "    \n",
    "#Try a more compartmentalised version of count_dict\n",
    "jnc_counts_dict_2 = {}\n",
    "\n",
    "for transcript, polya_dict in small_polya_jnc_coords.items():\n",
    "    \n",
    "    tr_polya_counts = {polya_site: sum(is_polya_junction_read(read, coords_tuple[1], 3) for read in wt_1.fetch(coords_tuple[0], \n",
    "                                                                            coords_tuple[1], \n",
    "                                                                            coords_tuple[2]))\n",
    "                       for polya_site, coords_tuple in polya_dict.items()}\n",
    "\n",
    "    jnc_counts_dict_2[transcript] = tr_polya_counts\n",
    "\n",
    "    \n",
    "#print(jnc_counts_dict_2)\n",
    "\n",
    "wt_1.close()\n",
    "\n",
    "def get_polya_junction_counts_dict(bam_path, jnc_coords_dict, sj_overhang):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    bam = pysam.AlignmentFile(bam_path, \"rb\")\n",
    "    \n",
    "    #final output dict of {tr: {site_id: jnc_counts}}\n",
    "    counts_dict = {}\n",
    "    \n",
    "    for transcript, polya_coords_dict in jnc_coords_dict.items():\n",
    "        \n",
    "        polya_coords_counts = {polya_site: sum(is_polya_junction_read(read,\n",
    "                                                                      coords_tuple[1],\n",
    "                                                                      sj_overhang) \n",
    "                                               \n",
    "                                               for read in bam.fetch(coords_tuple[0], \n",
    "                                                                     coords_tuple[1], \n",
    "                                                                     coords_tuple[2])\n",
    "                                              )\n",
    "                               for polya_site, coords_tuple in polya_coords_dict.items()}\n",
    "        \n",
    "        counts_dict[transcript] = polya_coords_counts\n",
    "        \n",
    "    \n",
    "    bam.close()\n",
    "    \n",
    "    return counts_dict\n",
    "\n",
    "wt_1_polya_jnc_counts = get_polya_junction_counts_dict(m323k_wt_1_bam_path, small_polya_jnc_coords, 3)\n",
    "hom_1_polya_jnc_counts = get_polya_junction_counts_dict(m323k_hom_1_bam_path, small_polya_jnc_coords, 3)\n",
    "\n",
    "#print(len(wt_1_polya_jnc_counts))\n",
    "#print(len(hom_1_polya_jnc_counts))\n",
    "\n",
    "print(wt_1_polya_jnc_counts)\n",
    "print(hom_1_polya_jnc_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now I need counts for junction reads at 5' end of terminal exon**\n",
    "\n",
    "The coordinates are provided in the paqr output table, - suggest pulling from the exon_id string\n",
    "\n",
    "Coordinates are bed-like i.e. 0-based, 1/2 open - start is included, end is not\n",
    "I want the splice junction coordinates to follow this\n",
    "if + strand then start of exon = start coordinate\n",
    "if - strand then start of exon = end coordinate (-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENSMUST00000000608': ('chr11', 55109377, 55109378), 'ENSMUST00000000844': ('chr2', 181515079, 181515080), 'ENSMUST00000000896': ('chr2', 154588091, 154588092), 'ENSMUST00000000985': ('chr14', 54368317, 54368318), 'ENSMUST00000001079': ('chr3', 129984005, 129984006)}\n",
      "{'ENSMUST00000000608': {'chr11:+:55110898:TE': ('chr11', 55110898, 55110899), 'chr11:+:55113026:TE': ('chr11', 55113026, 55113027)}, 'ENSMUST00000000844': {'chr2:+:181515384:TE': ('chr2', 181515384, 181515385), 'chr2:+:181515774:TE': ('chr2', 181515774, 181515775), 'chr2:+:181516756:TE': ('chr2', 181516756, 181516757)}, 'ENSMUST00000000896': {'chr2:-:154587124:TE': ('chr2', 154587124, 154587125), 'chr2:-:154585759:TE': ('chr2', 154585759, 154585760)}, 'ENSMUST00000000985': {'chr14:+:54368610:TE': ('chr14', 54368610, 54368611), 'chr14:+:54369669:TE': ('chr14', 54369669, 54369670)}, 'ENSMUST00000001079': {'chr3:-:129983184:TE': ('chr3', 129983184, 129983185), 'chr3:-:129982765:TE': ('chr3', 129982765, 129982766)}}\n"
     ]
    }
   ],
   "source": [
    "#Want dictionary of {transcript_id: (chr, start, end, )}\n",
    "\n",
    "#print(small_polya_jnc_coords)\n",
    "#print(rel_usages)\n",
    "\n",
    "def paqr_out_to_sj_coord_tuple(paqr_df, \n",
    "                               group_col = \"gene_id\",\n",
    "                               exon_colname = \"paqr_exon_id\",\n",
    "                               chr_colname = \"chr\", \n",
    "                               strand_colname = \"strand\"):\n",
    "    '''\n",
    "    Get dict of {transcript_id: (chr, start, end)} where coords are for 5' splice junction of terminal exon\n",
    "    '''\n",
    "    \n",
    "    out_dict = {}\n",
    "    \n",
    "    df_grouped = paqr_df.groupby(group_col)\n",
    "    \n",
    "    for group_name, group in df_grouped:\n",
    "        \n",
    "        \n",
    "        # Every id should have same strand, chromosome and terminal exon string, so only need 1 row\n",
    "        # List selection ensures return a dataframe\n",
    "        group = group.iloc[[0]]\n",
    "        \n",
    "        #exon id like ENSMUST00000007216:12:12:20543310:20544909\n",
    "        exon_split = group[exon_colname].to_string(index = False).split(':')\n",
    "        \n",
    "        if (group[strand_colname] == \"+\").bool():\n",
    "            #5 coord = start of te (& start coord = actual start)\n",
    "                        \n",
    "            coord_tuple = tuple([group[chr_colname].to_string(index = False).lstrip(' '),\n",
    "                                int(exon_split[-2]),\n",
    "                                int(exon_split[-2]) + 1\n",
    "                                ])\n",
    "            \n",
    "        elif (group[strand_colname] == \"-\").bool():\n",
    "            #5 of exon = end coord in string (half-open, so actual start coord = end -1)\n",
    "            \n",
    "            coord_tuple = tuple([group[chr_colname].to_string(index = False).lstrip(' '),\n",
    "                                int(exon_split[-1]) -1,\n",
    "                                int(exon_split[-1])\n",
    "                                ])\n",
    "            \n",
    "        out_dict[group_name] = coord_tuple\n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n",
    "splice_jnc_coords = paqr_out_to_sj_coord_tuple(rel_usages)\n",
    "#print(splice_jnc_coords)\n",
    "\n",
    "\n",
    "#Now lets make a small_splice_jnc_coords with same sjs as in small_polya_jnc_coords\n",
    "\n",
    "small_splice_jnc_coords = {key: val for key, val in splice_jnc_coords.items() \n",
    "                           if key in small_polya_jnc_coords.keys()}\n",
    "\n",
    "print(small_splice_jnc_coords)\n",
    "print(small_polya_jnc_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENSMUST00000000608': 310, 'ENSMUST00000000844': 450, 'ENSMUST00000000896': 30, 'ENSMUST00000000985': 183, 'ENSMUST00000001079': 192}\n",
      "{'ENSMUST00000000608': {'chr11:+:55110898:TE': 3, 'chr11:+:55113026:TE': 1}, 'ENSMUST00000000844': {'chr2:+:181515384:TE': 212, 'chr2:+:181515774:TE': 102, 'chr2:+:181516756:TE': 26}, 'ENSMUST00000000896': {'chr2:-:154587124:TE': 16, 'chr2:-:154585759:TE': 0}, 'ENSMUST00000000985': {'chr14:+:54368610:TE': 64, 'chr14:+:54369669:TE': 4}, 'ENSMUST00000001079': {'chr3:-:129983184:TE': 49, 'chr3:-:129982765:TE': 1}}\n",
      "{'ENSMUST00000000608': 475, 'ENSMUST00000000844': 482, 'ENSMUST00000000896': 48, 'ENSMUST00000000985': 244, 'ENSMUST00000001079': 196}\n",
      "{'ENSMUST00000000608': {'chr11:+:55110898:TE': 2, 'chr11:+:55113026:TE': 0}, 'ENSMUST00000000844': {'chr2:+:181515384:TE': 268, 'chr2:+:181515774:TE': 90, 'chr2:+:181516756:TE': 27}, 'ENSMUST00000000896': {'chr2:-:154587124:TE': 20, 'chr2:-:154585759:TE': 0}, 'ENSMUST00000000985': {'chr14:+:54368610:TE': 66, 'chr14:+:54369669:TE': 15}, 'ENSMUST00000001079': {'chr3:-:129983184:TE': 51, 'chr3:-:129982765:TE': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Ok now need to search bam for reads overlapping splice jnc coord,\n",
    "## count number of aligned reads crossing splice junction\n",
    "## \n",
    "\n",
    "def get_splice_junction_counts_dict(bam_path, jnc_coords_dict):\n",
    "    '''\n",
    "    output dict of {tr: count}\n",
    "    '''\n",
    "\n",
    "    bam = pysam.AlignmentFile(bam_path, \"rb\")\n",
    "    \n",
    "    #final output dict of {tr: {site_id: jnc_counts}}\n",
    "    counts_dict = {transcript: (sum(1 for read in bam.fetch(coords_tuple[0], \n",
    "                                              coords_tuple[1], \n",
    "                                              coords_tuple[2])))\n",
    "                  for transcript, coords_tuple in jnc_coords_dict.items()}\n",
    "    \n",
    "    bam.close()\n",
    "    \n",
    "    return counts_dict\n",
    "\n",
    "wt_1_splice_jnc_counts = get_splice_junction_counts_dict(m323k_wt_1_bam_path, small_splice_jnc_coords)\n",
    "hom_1_splice_jnc_counts = get_splice_junction_counts_dict(m323k_hom_1_bam_path, small_splice_jnc_coords)\n",
    "\n",
    "print(wt_1_splice_jnc_counts)\n",
    "print(wt_1_polya_jnc_counts)\n",
    "\n",
    "print(hom_1_splice_jnc_counts)\n",
    "print(hom_1_polya_jnc_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These counts are way way off...\n",
    "\n",
    "I think I'm going to actually have to do some smart filtering to get junction read counts\n",
    "\n",
    "i.e. for every read in bam.fetch(splice junction), check read is\n",
    "primary alignment/uniquely aligned\n",
    "\n",
    "is a split alignment i.e has 'N' in cigar string & this split alignment starts at the splice junction i.e. read skips a bit of reference sequence (intron) then starts at splice junction with contiguous/consective alignment to reference (i.e. exon)\n",
    "\n",
    "`~~~` - intron\n",
    "\n",
    "`___ `- exon\n",
    "\n",
    "`|` - splice junction\n",
    "\n",
    "`------` - read\n",
    "\n",
    "I'm interested in reads spanning  the splice junction of 'exon 2' (i.e. the TE)\n",
    "\n",
    "What i'm really after is the total number of reads supporting inclusion of/crossing this junction\n",
    "I'm not particularly interested which upstream exon/ splice junction it is spliced to, just that it supports inclusion of the terminal exon junction\n",
    "\n",
    "If I want to make sure it is a read connecting two exons (but without caring what the other junction is), I can check the cigar string such that the intron (N) is bounded by exact reference matches of at least (3) nt on either side e.g. a string like\n",
    "**70M84N5M** or for readability **70M 84N 5M** \n",
    "would be a valid read because a reference gap of 84N (intron) is separated by a consecutive match to reference (exon) >= 3nt on either side\n",
    "\n",
    "To be extra sure, I should really check the N & M segments align with reference coordinate/junction I'm interested in...\n",
    "\n",
    "**to this end, I just want reads that cross the TE splice junction, and contain a 'right hand overhang'. --alignSJDBoverhangMin, of at least x nt (default 3nt) i.e. x nt of the terminal exon** \n",
    "\n",
    "Maybe also only want to count spliced alignments, but for now let's not worry about that??\n",
    "\n",
    "\n",
    "5' exon 1                            exon 2            3'\n",
    "\n",
    "`____________|~~~~~~~~~~~~~~~~~~|______________`\n",
    "\n",
    "`xxxxxx-------NNNNNNNNNNNNNNNNNN-------xxxxxxxx` Read supporting splicing-in/inclusion of this TE\n",
    "\n",
    "`xx-----------NNNNNNNNNNNNNNNNNN--xxxxxxxxxxxxx`\n",
    "\n",
    "`xxxxxxxxxxxxxxxxxxxxxxxxxxxx----------------xx`\n",
    "\n",
    "\n",
    "check if right hand overhang is > --alignSJDBoverhangMin (usually 3nt) i.e. aligned portion of read has at least 3nt of terminal exon sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has minimum overhang & is valid junction read\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "read has does not have minimum exon-exon overhang\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "Read does not have a putative exon-exon junction alignment\n",
      "158\n",
      "('chr14', 54368317, 54368318)\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "test_tr_splice_jnc_tuple = small_splice_jnc_coords.get('ENSMUST00000000985')\n",
    "#print(test_tr_splice_jnc_tuple)\n",
    "\n",
    "wt_1 = pysam.AlignmentFile(m323k_wt_1_bam_path, \"rb\")\n",
    "\n",
    "x = 0\n",
    "\n",
    "\n",
    "#test_reads_dict = {}\n",
    "#for read in wt_1.fetch(test_tr_splice_jnc_tuple[0],\n",
    "#                    test_tr_splice_jnc_tuple[1],\n",
    "#                    test_tr_splice_jnc_tuple[2]):\n",
    "    \n",
    "#    while x < 10:\n",
    "#        if test_tr_splice_jnc_tuple in test_reads_dict.keys():\n",
    "#            #add AlignedSegment object for read to end of list for given splice jnc\n",
    "#            test_reads_dict[test_tr_splice_jnc_tuple].append(read.to_dict())\n",
    "#        \n",
    "#        else:\n",
    "#            test_reads_dict[test_tr_splice_jnc_tuple] = [read.to_dict()]\n",
    "#            \n",
    "#        x += 1\n",
    "#    else:\n",
    "#        break\n",
    "    \n",
    "#print(x)\n",
    "#print(test_reads_dict)\n",
    "\n",
    "'''\n",
    "cigartuples\n",
    "\n",
    "    the cigar alignment. The alignment is returned as a list of tuples of (operation, length).\n",
    "\n",
    "    If the alignment is not present, None is returned.\n",
    "\n",
    "    The operations are:\n",
    "    M \tBAM_CMATCH \t0\n",
    "    I \tBAM_CINS \t1\n",
    "    D \tBAM_CDEL \t2\n",
    "    N \tBAM_CREF_SKIP \t3\n",
    "    S \tBAM_CSOFT_CLIP \t4\n",
    "    H \tBAM_CHARD_CLIP \t5\n",
    "    P \tBAM_CPAD \t6\n",
    "    = \tBAM_CEQUAL \t7\n",
    "    X \tBAM_CDIFF \t8\n",
    "    B \tBAM_CBACK \t9\n",
    "\n",
    "\n",
    "I neeed to check for M followed by \n",
    "\n",
    "'''\n",
    "\n",
    "#spliced_read_test_count_dict = {}\n",
    "\n",
    "\n",
    "jnc_count = 0\n",
    "for read in wt_1.fetch(test_tr_splice_jnc_tuple[0],\n",
    "                    test_tr_splice_jnc_tuple[1],\n",
    "                    test_tr_splice_jnc_tuple[2]):\n",
    "    \n",
    "    # check for match (M) | reference skip/intron (N) | match (M)\n",
    "    parsed_cigar = read.cigartuples\n",
    "    #print(parsed_cigar)\n",
    "    #print(len(parsed_cigar))\n",
    "        \n",
    "    # Want to get indexes of Ms in a M | N | M sequence fro cigartuples\n",
    "    # (can then slice parsed_cigar to check whether Ms are long enough)\n",
    "    # M | N | M = [0, 3, 0] (in cigartuples looking to match to first element in each tuple)\n",
    "    seq_to_check = [0, 3, 0]\n",
    "        \n",
    "    #print(parsed_cigar[0:0+len(seq_to_check)])\n",
    "        \n",
    "        \n",
    "    cigar_check = [(i, i + len(seq_to_check) - 1) for i in range(len(parsed_cigar))\n",
    "                       if [tup[0] for tup in parsed_cigar[i:i + len(seq_to_check)]] == seq_to_check]\n",
    "        \n",
    "    #print(len(cigar_check))\n",
    "        \n",
    "    if len(cigar_check) > 0:\n",
    "        # Has a putative exon - exon alignment\n",
    "        # Now check if length of matched sequences is sufficient\n",
    "        for idx_start, idx_end in cigar_check:\n",
    "                \n",
    "            # Now check each string in matching sequence\n",
    "            if parsed_cigar[idx_start][1] > 3 and parsed_cigar[idx_end][1] > 3:\n",
    "                print(\"read has minimum overhang & is valid junction read\")\n",
    "                jnc_count += 1\n",
    "\n",
    "            else:\n",
    "                print(\"read does not have minimum exon-exon overhang\")\n",
    "                        \n",
    "                    \n",
    "    else:\n",
    "        print(\"Read does not have a putative exon-exon junction alignment\")            \n",
    "       \n",
    "        \n",
    "print(jnc_count)    \n",
    "\n",
    "print(test_tr_splice_jnc_tuple)\n",
    "#for col in wt_1.pileup(test_tr_splice_jnc_tuple[0],\n",
    "#                      test_tr_splice_jnc_tuple[1],\n",
    "#                      test_tr_splice_jnc_tuple[2]):\n",
    "#    print(\"coverage at position {0} : {1}\".format(col.pos, col.n))\n",
    "    \n",
    "count = 0\n",
    "for col in wt_1.fetch('chr2', 154588091, 154588092):\n",
    "    count +=1\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:polya_junctions] *",
   "language": "python",
   "name": "conda-env-polya_junctions-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
